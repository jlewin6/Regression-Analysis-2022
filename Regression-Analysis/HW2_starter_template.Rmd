---
title: "HW2 Peer Assessment"
output:
  html_document:
    df_print: paged
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Background

The fishing industry uses numerous measurements to describe a specific fish.  Our goal is to predict the weight of a fish based on a number of these measurements and determine if any of these measurements are insignificant in determining the weigh of a product.  See below for the description of these measurments.  

## Data Description

The data consists of the following variables:

1. **Weight**: weight of fish in g (numerical)
2. **Species**: species name of fish (categorical)
3. **Body.Height**: height of body of fish in cm (numerical)
4. **Total.Length**: length of fish from mouth to tail in cm (numerical)
5. **Diagonal.Length**: length of diagonal of main body of fish in cm (numerical)
6. **Height**: height of head of fish in cm (numerical)
7. **Width**: width of head of fish in cm (numerical)


## Read the data

```{r}
# Import library you may need
library(car)
library(PerformanceAnalytics)
library(dplyr)
library(MASS)
# set seed
set.seed(8675309)
# Read the data set
fishfull = read.csv("Fish.csv",header=T, fileEncoding = 'UTF-8-BOM')
row.cnt = nrow(fishfull)
# Split the data into training and testing sets
fishtest = fishfull[(row.cnt-9):row.cnt,]
fish = fishfull[1:(row.cnt-10),]
```

*Please use fish as your data set for the following questions unless otherwise stated.*

# Question 1: Exploratory Data Analysis [8 points]

**(a) Create a box plot comparing the response variable, *Weight*, across the multiple *species*.  Based on this box plot, does there appear to be a relationship between the predictor and the response?**

```{r}
boxplot(Weight~Species,
        main="",
        xlab="Species",
        ylab="Weight of fish (grams)",
        col=blues9,
        data=fish)

```

Yes, there is a relationship between the predictor and response variable. 

**(b) Create scatterplots of the response, *Weight*, against each quantitative predictor, namely **Body.Height**, **Total.Length**, **Diagonal.Length**, **Height**, and **Width**.  Describe the general trend of each plot.  Are there any potential outliers?**

```{r}
plot(fish)

```
Some really nice trends within this data set. We have great potential for some linear models with most of our predictor variables like "Width" having distinct linear trends, although there may be a few potential outliers. Some really heavy heavy fish skewing to the right in the "Weight" column. 


**(c) Display the correlations between each of the quantitative variables.  Interpret the correlations in the context of the relationships of the predictors to the response and in the context of multicollinearity.**

```{r}
temp_numeric <- select_if(fish, is.numeric) 
chart.Correlation(temp_numeric, histogram=TRUE, pch=19)

```



**(d) Based on this exploratory analysis, is it reasonable to assume a multiple linear regression model for the relationship between *Weight* and the predictor variables?**

Yes, I believe it is reasonable to assume the potential for a multiple linear regression model based on the observations above. 


# Question 2: Fitting the Multiple Linear Regression Model [8 points]

*Create the full model without transforming the response variable or predicting variables using the fish data set.  Do not use fishtest*

**(a) Build a multiple linear regression model, called model1, using the response and all predictors.  Display the summary table of the model.**

```{r}
model1 <- lm(Weight~., data=fish)
summary(model1)
```



**(b) Is the overall regression significant at an $\alpha$ level of 0.01? Explain.**
Yes, because the model p-value is < 2.2e-16. 


**(c) What is the coefficient estimate for *Body.Height*? Interpret this coefficient.**
-176.87
Increasing the the body height of the fish by one unit decreases the weight by approximately 177g holding all other predictor variables constant. 


**(d) What is the coefficient estimate for the *Species* category Parkki? Interpret this coefficient.**
79.34
If the fish is a Parkki the weight increases by approximately 79g holding the other predictor variables constant


# Question 3: Checking for Outliers and Multicollinearity [6 points]

**(a) Create a plot for the Cook's Distances. Using a threshold Cook's Distance of 1, identify the row numbers of any outliers.**

```{r}
# Cook’s Distance
cook = cooks.distance(model1)
sample_size = nrow(fish)
plot(cook, pch="*", cex=2, main="Influential Obs by Cooks distance")
abline(h = 1, col="red") 
text(x=1:length(cook)+1, y=cook, labels=ifelse(cook>1, names(cook),""), col="red") 
```



**(b) Remove the outlier(s) from the data set and create a new model, called model2, using all predictors with *Weight* as the response.  Display the summary of this model.**

```{r}
# influential row numbers
influential <- as.numeric(names(cook)[(cook > (1))])
fish2 <- fish[-influential, ]
model2<- lm(Weight~., data = fish2)
summary(model2)
```



**(c) Display the VIF of each predictor for model2. Using a VIF threshold of max(10, 1/(1-$R^2$) what conclusions can you draw?**

```{r}

round(vif(model2),3)

```

Body.Height, Total Length, Diagonal.Length all have high VIFs which A high indicates that the associated independent variables are highly collinear with the other variables in the model.


# Question 4: Checking Model Assumptions [6 points]

*Please use the cleaned data set, which have the outlier(s) removed, and model2 for answering the following questions.*

**(a) Create scatterplots of the standardized residuals of model2 versus each quantitative predictor. Does the linearity assumption appear to hold for all predictors?**

```{r}
resids = rstandard(model2)
fits = model2$fitted
# Extract the standardized residuals
plot(fish2$Body.Height, resids)
plot(fish2$Total.Length, resids)
plot(fish2$Diagonal.Length, resids)
plot(fish2$Height, resids)
plot(fish2$Width, resids)
```
Body.Height, Total.Length, and Diagonal Length all show some signs of curvature which indicates the linearity assumption may not hold for those variables. 


**(b) Create a scatter plot of the standardized residuals of model2 versus the fitted values of model2.  Does the constant variance assumption appear to hold?  Do the errors appear uncorrelated?**

```{r}
resids = rstandard(model2)
fits = model2$fitted

plot(fits, resids,
     xlab="Fitted Values",
     ylab="Residuals",
     main="")
abline(0, 0,
       lty=2, lwd=2)
```

No, the constant variance assumption does not hold, and there appears to be come correlation between the fitted values.

**(c) Create a histogram and normal QQ plot for the standardized residuals. What conclusions can you draw from these plots?**

```{r}
hist(resids)

```

a fairly normal distribution with a slight tail past 2. 


# Question 5: Partial F Test [6 points]

**(a) Build a third multiple linear regression model using the cleaned data set without the outlier(s), called model3, using only *Species* and *Total.Length* as predicting variables and *Weight* as the response.  Display the summary table of the model3.**

```{r}
model3<-lm(Weight~Species+Total.Length, data=fish2)
summary(model3)
```



**(b) Conduct a partial F-test comparing model3 with model2. What can you conclude using an $\alpha$ level of 0.01?**

```{r}
anova(model3, model2)

```
Since this p-value is not less than .01, we will fail to reject the null hypothesis. This means we don’t have sufficient evidence to say that either of the predictor variables Species or Total.Length are statistically significant.



# Question 6: Reduced Model Residual Analysis and Multicollinearity Test [7 points]

**(a) Conduct a multicollinearity test on model3.  Comment on the multicollinearity in model3.**
```{r}
vif(model3)

```
There doesn't seem to be much multicollinearity between the two variables in model3


**(b) Conduct residual analysis for model3 (similar to Q4). Comment on each assumption and whether they hold.**
```{r}
resids2 = rstandard(model3)
fits2 = model3$fitted

plot(fits2, resids2,
     xlab="Fitted Values",
     ylab="Residuals",
     main="")
abline(0, 0,
       lty=2, lwd=2)

```

It looks like the assumption of linearity may not entirely hold. There is some grouping between the fitted values and residuals.


# Question 7: Transformation [9 pts]

**(a) Use model3 to find the optimal lambda, rounded to the nearest 0.5, for a Box-Cox transformation on model3.  What transformation, if any, should be applied according to the lambda value?  Please ensure you use model3**

```{r}
bc <- boxcox(model3)
(lambda <- bc$x[which.max(bc$y)])

```

Optimal lambda is .343 which we will round to 0.5 

This lambda indicates we should take our Y variable and transform it using the squareroot approach. 

**(b) Based on the results in (a), create model4 with the appropriate transformation. Display the summary.**
```{r}
model4<- lm(sqrt(Weight)~., data=fish2)
summary(model4)

```



**(c) Perform Residual Analysis on model4. Comment on each assumption.  Was the transformation successful/unsuccessful?**
```{r}
resids2 = rstandard(model4)
fits2 = model4$fitted
# Extract the standardized residuals
plot(fish2$Body.Height, resids2)
plot(fish2$Total.Length, resids2)
plot(fish2$Diagonal.Length, resids2)
plot(fish2$Height, resids2)
plot(fish2$Width, resids2)
```

Yes, the transformation was generally successful. THe overall assumptions of lineararity appear more strongly. 


# Question 8: Model Comparison [2 pts]

**(a) Using each model summary, compare and discuss the R-squared and Adjusted R-squared of model2, model3, and model4.**

```{r}
summary1<-summary(model1)
summary2<-summary(model2)
summary3<-summary(model3)
summary4<-summary(model4)
c(summary1$r.squared,summary1$adj.r.squared) 
c(summary2$r.squared,summary2$adj.r.squared) 
c(summary3$r.squared,summary3$adj.r.squared) 
c(summary4$r.squared,summary4$adj.r.squared) 
```

Model4 has bettter r-squared and a better adjusted r-squared.


# Question 9: Prediction [8 points]

**(a) Predict Weight for the last 10 rows of data (fishtest) using both model3 and model4.  Compare and discuss the mean squared prediction error (MSPE) of both models.** 

```{r}

last_ten <- tail(fishtest,10)

pred1<-predict(model3, newdata=last_ten)

pred2<-predict(model4, newdata=last_ten)

# Mean Squared Prediction Error (MSPE)
mean((pred1-fishtest$Weight)^2)

mean((pred2-fishtest$Weight)^2)

```



**(b) Suppose you have found a Perch fish with a Body.Height of 28 cm, and a Total.Length of 32 cm. Using model4, predict the weight on this fish with a 90% prediction interval.  Provide an interpretation of the prediction interval.**

```{r}
model4_b<- lm(sqrt(Weight)~Species+Body.Height+Total.Length, data=fish2)
new.point<-data.frame(Species="Perch", Total.Length=32, Body.Height=28) # model4 has only one predictor; Total.length
# Calculate prediction interval
predict(model4_b, new.point, interval="prediction", level=0.9)^2
```


Based on the variables provided, the model predicts the fish will weigh approx 459g. With lower and upper bounds between 357g and 574g. 
